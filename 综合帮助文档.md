# MRI图像重建平台综合帮助文档

## 项目概述

这是一个功能强大的MRI（磁共振成像）图像重建与数据处理平台，专门为医学影像研究和工程应用设计。无论您是没有任何算法背景的新手，还是经验丰富的研究人员，都可以通过这个平台轻松完成MRI图像的重建和处理工作。

平台主要包含以下四大功能模块：
1. **传统重建模块** - 基础的图像重建方法
2. **压缩感知重建模块** - 先进的数学优化算法
3.com **深度学习重建模块** - 基于人工智能的重建方法
4. **数据处理工具模块** - 数据预处理和管理工具

## 项目文件结构详解

```
GUI_CSMRI/
├── MriRecon.py              # 主程序入口文件（启动整个软件）
├── Ui_ImageRecon2.py        # 界面代码（不要修改）
├── DL_params.json           # 深度学习模型配置文件（参数设置）
├── README.md                # 项目说明文档
├── DLCSMRI/                 # 深度学习相关模块（AI算法）
│   ├── unet.py             # U-Net模型训练代码
│   ├── UNetInference.py    # U-Net模型推理代码
│   ├── MoDL.py             # MoDL模型训练代码
│   ├── MoDLInference.py    # MoDL模型推理代码
│   ├── Transformer.py      # Transformer模型训练代码
│   ├── TransformerInference.py # Transformer模型推理代码
│   ├── ista.py             # ISTA-Net模型训练代码
│   └── ISTAInference.py    # ISTA-Net模型推理代码
├── Solver/                  # 传统算法和压缩感知算法模块（数学算法）
│   ├── ADMM_TV.py          # ADMM-TV算法实现
│   ├── ADMM_TV_CUPY.py     # GPU加速的ADMM-TV算法实现
│   ├── Wavelet_ISTA.py     # 小波-ISTA算法实现
│   ├── FFtTransform.py     # FFT变换实现
│   ├── NUFFtTransform.py   # NUFFT变换实现
│   ├── NUFFtWavelet.py     # NUFFt-小波算法实现
│   ├── mask_2d.py          # 2D掩码生成
│   └── ...
├── model/                   # 预训练模型权重文件（AI模型）
│   ├── U_Net.pth           # U-Net模型权重
│   ├── MoDL.pth            # MoDL模型权重
│   ├── Transformer.pth     # Transformer模型权重
│   ├── ISTA.pth            # ISTA-Net模型权重
│   └── ...
└── output_*/                # 各模型输出目录（结果保存）
```

## 软件启动和基本操作

### 启动软件
```bash
python MriRecon.py
```

### 界面导航
软件主界面分为四个主要功能页面，通过左侧的导航按钮切换：
- **传统重建** - 基础的傅里叶变换重建方法
- **压缩感知** - 高级数学优化算法
- **深度学习** - 基于人工智能的重建方法
- **数据处理** - 数据预处理和模型训练工具

## 第一部分：传统重建模块详解

### 什么是传统重建？
传统重建基于傅里叶变换理论，是MRI图像重建的基础方法。它将采集到的k空间数据通过傅里叶逆变换转换为图像域。

### 核心思想（通俗解释）
想象k空间是MRI数据的"配方"，传统重建就像按照配方一步步还原出最终的图像。k空间中的每个点都包含图像的频率信息，通过傅里叶变换把这些信息组合起来就能得到清晰的MRI图像。

### 适用场景
- 完整采样的k空间数据
- 标准的笛卡尔网格采样
- 需要快速获得基础重建结果

### 算法类型

#### 1. FFT变换（快速傅里叶变换）
**原理**：对标准的笛卡尔网格采样数据执行快速傅里叶变换。

**适用场景**：
- 标准MRI扫描数据
- 完整采样的k空间数据
- 需要快速重建的基础应用

#### 2. NUFFT变换（非均匀快速傅里叶变换）
**原理**：对非笛卡尔采样轨迹（如径向、螺旋）的数据执行非均匀快速傅里叶变换。

**适用场景**：
- 径向采样轨迹数据
- 螺旋采样轨迹数据
- 非标准采样模式的数据重建

### 第一部分：传统重建页面详解

#### 页面布局
传统重建页面分为左右两个区域：
- **左侧控制区**：参数设置和操作按钮
- **右侧显示区**：重建结果展示

#### 左侧控制区详细说明

##### 1. 传统重建参数标题
- **位置**：页面顶部
- **功能**：标识当前页面功能
- **内容**："传统重建参数"

##### 2. kspace数据文件选择区
- **标签**："kspace数据文件"
- **按钮**："选择文件"
- **功能**：选择包含k空间数据的文件夹
- **操作说明**：
  1. 点击"选择文件"按钮
  2. 在弹出的文件浏览器中选择包含.npy格式k空间数据文件的文件夹
  3. 选择后路径会显示在按钮上方的标签中

##### 3. 采样轨迹数据文件选择区
- **标签**："采样轨迹数据文件（非笛卡尔采样）"
- **按钮**："选择文件"
- **功能**：选择非笛卡尔采样轨迹文件（仅在选择非笛卡尔采样时需要）
- **操作说明**：
  1. 仅当"重建类型"选择"非笛卡尔采样"时才需要
  2. 点击"选择文件"按钮
  3. 选择包含轨迹数据的.npy文件

##### 4. 重建类型选择区
- **标签**："重建类型"
- **下拉框**：包含两个选项
  - "笛卡尔采样"：标准的网格采样数据重建
  - "非笛卡尔采样"：径向、螺旋等非标准采样轨迹数据重建
- **功能**：选择数据的采样类型
- **默认值**："笛卡尔采样"

##### 5. 导出选项
- **复选框**："是否导出原始数据"
- **功能**：控制是否同时保存.npy格式的原始数据文件
- **默认状态**：勾选（导出原始数据）
- **操作说明**：
  - 勾选：同时保存.png图像文件和.npy数据文件
  - 不勾选：只保存.png图像文件

##### 6. 执行重建按钮
- **按钮**："执行重建"
- **功能**：开始执行图像重建过程
- **操作说明**：
  1. 确保已选择k空间数据文件
  2. 如需要，选择轨迹文件
  3. 设置重建类型和导出选项
  4. 点击"执行重建"按钮
  5. 在弹出的对话框中选择输出文件夹
  6. 等待重建完成，结果会显示在右侧区域

#### 右侧显示区
- **标题**："重建图像展示："
- **功能**：显示重建完成的图像结果
- **显示内容**：重建后的MRI图像，支持放大、缩小、移动等操作

## 第二部分：压缩感知重建模块详解

### 什么是压缩感知（Compressed Sensing）？
压缩感知是一种革命性的信号采集和重建理论，它允许我们用远少于传统理论要求的采样点来重建高质量的图像。这对于MRI来说意味着可以大幅缩短扫描时间。

### 核心思想（通俗解释）
想象你要画一幅画，传统方法是把画布上每个点的颜色都精确记录下来。而压缩感知就像一个聪明的画家，只需要记录关键的几个点，就能根据这些点推断出整幅画的全貌。

在MRI中：
- **传统方法**：需要采集完整的k空间数据（大量采样点）
- **压缩感知**：只需要采集部分k空间数据（少量采样点），通过算法重建完整图像

### 算法1：ADMM-TV（交替方向乘子法+全变分）

#### 算法原理（通俗解释）
ADMM-TV结合了两个强大的概念：
1. **ADMM（交替方向乘子法）**：一种优化算法，像一个聪明的侦探，通过分步骤解决复杂问题
2. **TV（全变分）**：假设图像中相邻像素的变化不会太大，保持图像的平滑性

#### 参数说明
- **tv_r（TV正则化参数）**：控制图像平滑程度，值越大图像越平滑（默认5）
- **rho（ADMM惩罚参数）**：控制优化过程的严格程度（默认1）
- **n_iter（迭代次数）**：算法重复计算的次数，越多结果越精确但耗时越长（默认50）
- **step（步长）**：每次计算的步长大小（默认0.5）

#### 适用场景
- 适合1D随机采样掩码
- 重建速度较快
- 对噪声有一定的抑制能力

#### 调用方式
在主程序中通过`ADMM_TV.process_kspace_files()`函数调用

### 算法2：Wavelet-ISTA（小波变换+迭代软阈值算法）

#### 算法原理（通俗解释）
Wavelet-ISTA利用了图像在小波域的稀疏性：
1. **小波变换**：将图像转换到小波域，大部分信息集中在少数系数上
2. **ISTA（迭代软阈值算法）**：通过迭代优化，逐步逼近真实图像

#### 参数说明
- **epsilon（收敛阈值）**：控制算法停止的精度（默认1e-4）
- **n_max（最大迭代次数）**：最大迭代次数（默认50）
- **tol（容差）**：收敛判断的容差（默认1e-4）
- **decfac（衰减因子）**：控制正则化参数的衰减速度（默认0.5）
- **threshold（小波阈值）**：小波系数的阈值（默认5）
- **wavelet（小波类型）**：使用的小波基函数（默认'haar'）
- **level（小波分解层数）**：小波分解的层数（默认2）

#### 适用场景
- 适合具有稀疏特性的图像
- 能保留更多图像细节
- 对纹理丰富的图像效果更好

#### 调用方式
在主程序中通过`Wavelet_ISTA.process_kspace_files()`函数调用

### 算法3：ADMM-TV-CuPy（GPU加速版本）

#### 算法原理
这是ADMM-TV算法的GPU加速版本，利用CuPy库在NVIDIA GPU上进行并行计算，大幅提高处理速度。

#### 适用场景
- 需要快速处理大量数据
- 有NVIDIA GPU硬件支持
- 对处理时间有严格要求

#### 调用方式
在主程序中通过`ADMM_TV_CUPY.process_kspace_files()`函数调用

### 算法4：NUFFt-Wavelet（非均匀FFT+小波）

#### 算法原理
专为处理非笛卡尔采样轨迹（如径向、螺旋）设计，结合了非均匀快速傅里叶变换和小波稀疏性。

#### 适用场景
- 径向采样轨迹
- 螺旋采样轨迹
- 非标准采样模式

#### 调用方式
在主程序中通过`NUFFtWavelet.process_kspace_files()`函数调用

### 第二部分：压缩感知重建页面详解

#### 页面布局
压缩感知重建页面同样分为左右两个区域：
- **左侧控制区**：参数设置和操作按钮
- **右侧显示区**：重建结果展示和参数表格

#### 左侧控制区详细说明

##### 1. 压缩感知重建参数标题
- **位置**：页面顶部
- **功能**：标识当前页面功能
- **内容**："压缩感知重建参数"

##### 2. kspace降采样数据文件选择区
- **标签**："kspace降采样数据文件"
- **按钮**："选择文件"
- **功能**：选择包含欠采样k空间数据的文件夹
- **操作说明**：
  1. 点击"选择文件"按钮
  2. 选择包含欠采样.npy文件的文件夹
  3. 支持批量处理多个文件

##### 3. 采样掩码/轨迹数据文件选择区
- **标签**："采样掩码/轨迹数据文件"
- **按钮**："选择文件"
- **功能**：选择对应的采样掩码或轨迹文件
- **操作说明**：
  1. 点击"选择文件"按钮
  2. 选择对应的.npy格式掩码或轨迹文件

##### 4. 重建算法选择区
- **标签**："重建算法"
- **下拉框**：包含四个选项
  - "0-总变分（TV）"：基于全变分正则化的ADMM算法
  - "1-小波变换（L1最小化）"：基于小波稀疏性的ISTA算法
  - "2-非均匀（小波变换）"：适用于非笛卡尔采样的小波算法
  - "3-总变分（支持GPU加速）"：GPU加速版本的TV算法
- **功能**：选择要使用的压缩感知重建算法
- **默认值**："0-总变分（TV）"

##### 5. 算法参数设置区
根据选择的不同算法，右侧会显示对应的参数设置表格：

###### 算法0和算法3（总变分）参数表
- **n_iter**：迭代数，默认值50，控制算法迭代次数
- **tv_r**：TV权重，默认值10，控制图像平滑程度
- **rho**：ADMM系数，默认值1，控制优化过程严格程度
- **step**：更新步长，默认值0.5，控制每次更新的步长
- **cg_iter**：共轭梯度迭代，默认值3，控制内部优化迭代次数
- **tv_ndim**：维度TV，默认值2，图像维度设置

###### 算法1（小波变换）参数表
- **n_iter**：迭代数，默认值50
- **epsilon**：收敛阈值，默认值0.0001，控制算法停止精度
- **tol**：容差，默认值0.0001，收敛判断容差
- **decfac**：L1衰减因子，默认值0.5，正则化参数衰减速度
- **threshold**：小波阈值，默认值1，小波系数阈值
- **wavelet**：小波类型，默认值"haar"，使用的小波基函数
- **level**：小波分解层数，默认值2，小波分解层数

###### 算法2（非均匀小波）参数表
- **image_size**：图像尺寸，默认值256
- **eps**：收敛阈值，默认值0.01
- **tol**：容差，默认值0.00001
- **L**：Lipschitz常数，默认值0.01
- **lamda**：L1权重，默认值0.1
- **max_iter**：迭代数，默认值80

##### 6. 导出选项
- **复选框**："是否导出原始数据"
- **功能**：控制是否同时保存.npy格式的原始数据文件
- **默认状态**：勾选
- **操作说明**：
  - 勾选：同时保存.png图像文件和.npy数据文件
  - 不勾选：只保存.png图像文件

##### 7. 执行重建按钮
- **按钮**："执行重建"
- **功能**：开始执行压缩感知图像重建过程
- **操作说明**：
  1. 选择欠采样k空间数据文件夹
  2. 选择对应的掩码或轨迹文件
  3. 选择重建算法
  4. 根据需要调整参数表格中的数值
  5. 设置导出选项
  6. 点击"执行重建"按钮
  7. 在弹出的对话框中选择输出文件夹
  8. 等待重建完成，结果会显示在右侧区域

#### 右侧显示区
- **标题**："重建图像展示："
- **功能**：显示重建完成的图像结果和参数设置区域

## 第三部分：深度学习重建模块详解

### 什么是深度学习MRI重建？
深度学习MRI重建使用人工智能神经网络来学习从欠采样数据到高质量图像的映射关系。相比传统算法，深度学习方法通常能获得更好的重建质量。

### 模型1：U-Net

#### 模型结构（通俗解释）
U-Net是一种经典的编码器-解码器结构：
1. **编码器**：像一个摄影师，逐步提取图像的高层次特征
2. **解码器**：像一个画家，根据提取的特征重新绘制完整图像
3. **跳跃连接**：像一座桥梁，将低层次的细节信息传递给高层次

#### 模型特点
- 结构简单，易于理解和实现
- 在医学图像处理中表现优秀
- 训练相对稳定

#### 配置参数（DL_params.json中）
```json
{
  "U-Net": {
    "DEVICE": "cpu",           // 运行设备（cpu或cuda）
    "BATCH_SIZE": 8,           // 批次大小
    "NUM_WORKERS": 6,          // 数据加载线程数
    "LEARNING_RATE": 1e-4,     // 学习率
    "WEIGHT_DECAY": 5e-5,      // 权重衰减
    "NUM_EPOCHS": 1000,        // 训练轮数
    "CHECKPOINT_PATH": "./model/U_Net.pth",  // 模型保存路径
    "RESUME_TRAINING": true,   // 是否恢复训练
    "OUTPUT_DIR": "./output_UNET",  // 输出目录
    "IN_CHANNELS": 1,          // 输入通道数
    "OUT_CHANNELS": 1,         // 输出通道数
    "IMAGE_SIZE": 256          // 图像大小
  }
}
```

#### 训练调用
```bash
python DLCSMRI/unet.py
```

#### 推理调用
在主程序中通过`UNetInference`模块调用

### 模型2：MoDL（Model-Based Deep Learning）

#### 模型结构（通俗解释）
MoDL将传统的迭代优化算法展开为深度网络：
1. **物理模型**：保持了MRI物理规律的约束
2. **数据驱动**：利用神经网络学习最优参数
3. **优势**：结合了物理模型的可靠性和深度学习的灵活性

#### 模型特点
- 理论基础扎实
- 重建质量高
- 泛化能力强

#### 配置参数
```json
{
  "MoDL": {
    "DEVICE": "cpu",
    "train": {
      "batch_size": 4,
      "learning_rate": 1e-4,
      "epochs": 1000
    },
    "optim": {
      "num_iters": 8,      // 迭代次数
      "channels": 256,     // 通道数
      "lambda_init": 0.1   // 初始正则化参数
    }
  }
}
```

#### 训练调用
```bash
python DLCSMRI/MoDL.py
```

#### 推理调用
在主程序中通过`MoDLInference`模块调用

### 模型3：Transformer

#### 模型结构（通俗解释）
Transformer使用自注意力机制：
1. **自注意力**：能够关注图像中所有位置之间的关系
2. **全局建模**：可以捕捉长距离依赖关系
3. **并行处理**：计算效率高

#### 模型特点
- 捕捉全局信息能力强
- 适合处理复杂纹理
- 计算资源需求较大

#### 配置参数
```json
{
  "Transformer": {
    "DEVICE": "cpu",
    "BATCH_SIZE": 4,
    "model": {
      "patch_size": 16,     // 图像块大小
      "embed_dim": 512,     // 嵌入维度
      "num_heads": 16,      // 注意力头数
      "num_layers": 12,     // 层数
      "num_residual_blocks": 8  // 残差块数
    }
  }
}
```

#### 训练调用
```bash
python DLCSMRI/Transformer.py
```

#### 推理调用
在主程序中通过`TransformerInference`模块调用

### 模型4：ISTA-Net

#### 模型结构（通俗解释）
ISTA-Net将ISTA迭代过程展开为深度网络：
1. **迭代展开**：将传统迭代算法的每一步映射为网络层
2. **参数学习**：让网络自动学习最优的阈值和字典
3. **优势**：结合了优化理论和深度学习

#### 模型特点
- 理论指导设计
- 可解释性强
- 收敛性有保证

#### 配置参数
```json
{
  "ISTA": {
    "DEVICE": "cpu",
    "optim": {
      "num_iters": 8,       // 迭代次数
      "channels": 256,      // 通道数
      "rho_init": 0.1       // 初始参数
    }
  }
}
```

#### 训练调用
```bash
python DLCSMRI/ista.py
```

#### 推理调用
在主程序中通过`ISTAInference`模块调用

### 第三部分：深度学习重建页面详解

#### 页面布局
深度学习重建页面分为左右两个区域：
- **左侧控制区**：参数设置和操作按钮
- **右侧显示区**：重建结果展示

#### 左侧控制区详细说明

##### 1. 深度学习重建参数标题
- **位置**：页面顶部
- **功能**：标识当前页面功能
- **内容**："深度学习重建参数"

##### 2. 源文件路径选择区
- **标签**："源文件路径（val/kspace；val/mask）"
- **按钮**："选择文件"
- **功能**：选择包含验证数据的文件夹
- **操作说明**：
  1. 点击"选择文件"按钮
  2. 选择包含val子文件夹的目录
  3. val文件夹内应包含kspace和mask子文件夹

##### 3. 导出结果路径选择区
- **标签**："选择导出结果路径"
- **按钮**："选择文件"
- **功能**：选择重建结果的保存位置
- **操作说明**：
  1. 点击"选择文件"按钮
  2. 选择希望保存结果的文件夹

##### 4. 模型选择区
- **标签**："选择模型"
- **下拉框**：包含四个选项
  - "U-Net"：经典的编码器-解码器结构
  - "MoDL"：基于模型的深度学习
  - "Transformer"：基于注意力机制的模型
  - "ISTA"：基于迭代软阈值的网络
- **功能**：选择要使用的深度学习模型
- **默认值**："U-Net"

##### 5. 导出选项
- **复选框**："是否导出原始数据"
- **功能**：控制是否同时保存.npy格式的原始数据文件
- **默认状态**：勾选
- **操作说明**：
  - 勾选：同时保存.png图像文件和.npy数据文件
  - 不勾选：只保存.png图像文件

##### 6. 执行重建按钮
- **按钮**："执行重建"
- **功能**：开始执行深度学习图像重建过程
- **操作说明**：
  1. 选择源文件路径
  2. 选择导出结果路径
  3. 选择要使用的模型
  4. 设置导出选项
  5. 点击"执行重建"按钮
  6. 等待重建完成，结果会显示在右侧区域

##### 7. 模型说明区域
- **内容**：
  1. U-Net模型支持笛卡尔以及非笛卡尔采样重建，其不需要加载采样掩码数据文件，是端到端的深度学习模型；
  2. 其余模型暂时只支持笛卡尔采样重建，并且另外需要加载采样掩码；

#### 右侧显示区
- **标题**："重建图像展示："
- **功能**：显示重建完成的图像结果对比
- **显示内容**：左侧显示欠采样输入图像，右侧显示AI重建结果

## 第四部分：数据处理模块详解

### 数据处理工具概述
数据处理模块提供了一套完整的工具链，用于构建深度学习数据集和进行数据预处理。

### 核心功能

#### 1. 创建数据集结构
- **功能**：一键生成符合训练要求的标准文件夹结构
- **结构**：
  ```
  dataset/
  ├── train/
  │   ├── full/
  │   ├── undersampled/
  │   └── mask/
  └── val/
      ├── full/
      ├── undersampled/
      └── mask/
  ```

#### 2. FID文件转换
- **功能**：将原始的MRI FID（Free Induction Decay）数据文件转换为常见的图像格式（如PNG）或k-space数据

#### 3. 图像分组
- **功能**：将一个文件夹中的所有图像文件平均分成指定数量的组，便于数据划分

#### 4. 生成欠采样数据与掩码
- **功能**：将输入的全采样图像转换为k-space，然后根据选定的掩码或轨迹生成对应的欠采样k-space和掩码文件

#### 5. 批量重命名
- **功能**：为文件批量添加后缀，并复制到指定输出目录

#### 6. 划分训练/验证集
- **功能**：从训练集中随机抽取指定比例的数据作为验证集，并自动移动到相应的验证文件夹

### 第四部分：数据处理页面详解

#### 页面布局
数据处理页面功能最为丰富，包含多个子功能区域：
- **顶部标题**："数据处理与模型训练"
- **功能区域**：多个数据处理工具按垂直顺序排列

#### 功能区域详细说明

##### 1. 初始化数据集
- **标签**："初始化数据集"
- **按钮**："创建数据集路径"
- **功能**：创建标准的深度学习训练数据集结构
- **操作说明**：
  1. 点击"创建数据集路径"按钮
  2. 选择要创建数据集的目录
  3. 程序会自动创建标准文件夹结构

##### 2. 格式转换（FID->PNG）
- **标签**："格式转换（FID->PNG）"
- **按钮组合**：
  - "加载数据"：选择包含FID文件的文件夹
  - "执行转换"：开始格式转换过程
- **功能**：将原始MRI FID数据文件转换为PNG图像格式
- **操作说明**：
  1. 点击"加载数据"按钮选择FID文件夹
  2. 点击"执行转换"按钮开始转换
  3. 转换后的PNG文件会保存在指定位置

##### 3. 数据分组
- **标签**："数据分组(各组进行相应处理)"
- **按钮组合**：
  - "加载数据"：选择要分组的图像文件夹
  - "执行分组"：开始分组过程
- **功能**：将大量图像文件平均分成指定数量的组
- **操作说明**：
  1. 点击"加载数据"按钮选择图像文件夹
  2. 点击"执行分组"按钮开始分组
  3. 程序会提示输入分组数量
  4. 图像会被平均分配到不同组中

##### 4. 批量修改文件名
- **标签**："批量修改文件名"
- **按钮组合**：
  - "加载数据"：选择要重命名的文件夹
  - "执行修改"：开始重命名过程
- **功能**：为文件批量添加后缀并复制到指定目录
- **操作说明**：
  1. 点击"加载数据"按钮选择源文件夹和目标文件夹
  2. 点击"执行修改"按钮开始重命名
  3. 程序会提示输入要添加的后缀
  4. 文件会被重命名并复制到目标文件夹

##### 5. 降采样kspace与mask/traj生成
- **标签**："降采样kspace与mask/traj生成"
- **下拉框**："选择采样类型"，包含六个选项：
  - "相位随机"：相位编码方向随机采样
  - "位置随机"：中心矩形区域保留的随机采样
  - "径向（均匀）"：均匀分布的径向采样
  - "螺旋（均匀）"：均匀分布的螺旋采样
  - "径向（非均匀）"：非均匀分布的径向采样
  - "螺旋（非均匀）"：非均匀分布的螺旋采样
- **参数表格**：根据选择的采样类型显示对应参数
- **按钮组合**：
  - "加载数据"：选择源图像文件夹和输出文件夹
  - "生成unkspace/mask/traj"：开始生成过程
- **功能**：从完整采样图像生成对应的欠采样k空间数据和掩码/轨迹
- **操作说明**：
  1. 选择采样类型
  2. 根据需要调整参数表格中的数值
  3. 点击"加载数据"按钮选择输入和输出文件夹
  4. 点击"生成unkspace/mask/traj"按钮开始生成
  5. 生成的文件会保存在指定的输出文件夹中

##### 6. 划分训练集与验证集
- **标签**："加载数据与训练"
- **输入框**：验证集比例（默认0.75）
- **按钮**："划分训练集与验证集"
- **功能**：从训练集中随机抽取指定比例的数据作为验证集
- **操作说明**：
  1. 选择包含train文件夹的目录
  2. 在输入框中设置验证集比例（如0.75表示75%作为验证集）
  3. 点击"划分训练集与验证集"按钮
  4. 程序会自动移动文件并创建val文件夹

##### 7. 模型训练
- **标签**："选择模型&训练"
- **下拉框**：包含四个选项
  - "U-Net"：训练U-Net模型
  - "MoDL"：训练MoDL模型
  - "Transformer"：训练Transformer模型
  - "ISTA"：训练ISTA-Net模型
- **按钮**："开始训练"
- **功能**：使用准备好的数据集训练深度学习模型
- **操作说明**：
  1. 确保已经创建了标准数据集结构
  2. 选择要训练的模型类型
  3. 点击"开始训练"按钮
  4. 训练过程会在控制台显示进度
  5. 训练完成后模型权重会保存在model文件夹中

#### 右侧显示区
- **标题**："图像展示区"
- **功能**：显示数据处理过程中的图像结果
- **显示内容**：根据当前操作显示相应的图像预览

## 使用流程建议

### 新手使用流程
1. **准备数据**：
   - 使用"数据处理"页面的"初始化数据集"功能创建标准文件夹结构
   - 准备完整的MRI图像数据

2. **生成训练数据**：
   - 使用"降采样kspace与mask/traj生成"功能创建欠采样数据
   - 使用"划分训练集与验证集"功能分离训练和验证数据

3. **训练模型**（可选）：
   - 如果需要定制化模型，使用"模型训练"功能训练专属模型

4. **执行重建**：
   - 根据数据类型选择合适的重建页面
   - 传统重建：适用于标准采样数据
   - 压缩感知：适用于欠采样数据，需要掩码文件
   - 深度学习：适用于欠采样数据，效果通常最好

### 高级用户使用流程
1. **快速重建**：
   - 直接使用预训练的深度学习模型进行重建
   - 根据数据特点选择合适的压缩感知算法

2. **模型优化**：
   - 使用自己的数据重新训练模型
   - 调整算法参数以获得最佳效果

3. **批量处理**：
   - 准备好批量数据文件夹
   - 一次性处理大量数据文件

## 常见问题解答

### Q1: 如何选择合适的重建算法？
**A**: 
- 如果数据是完整采样的：使用"传统重建"
- 如果数据是欠采样的：
  - 追求速度：选择"总变分（TV）"算法
  - 追求质量：选择深度学习模型
  - 有GPU：选择GPU加速版本

### Q2: 为什么深度学习重建效果最好？
**A**: 
深度学习模型经过大量数据训练，能够学习到更复杂的图像特征和重建模式，因此通常能获得最佳的重建质量。

### Q3: 参数如何调整？
**A**: 
- 迭代次数：增加可提高质量但会增加时间
- 正则化参数：根据图像噪声水平调整
- 学习率：深度学习中影响训练稳定性

### Q4: 数据格式要求？
**A**: 
- k空间数据：.npy格式的numpy数组
- 图像数据：.png格式的灰度图像
- 掩码/轨迹：.npy格式的numpy数组

### Q5: 如何处理非笛卡尔采样数据？
**A**: 
- 在"传统重建"中选择"非笛卡尔采样"类型
- 在"压缩感知"中选择算法2或算法3
- 需要提供对应的轨迹文件

## 注意事项

1. **文件路径**：避免使用包含中文或特殊字符的路径
2. **内存管理**：处理大图像时注意系统内存使用
3. **GPU支持**：使用GPU加速需要安装相应的CUDA驱动
4. **数据备份**：重要数据请提前备份
5. **参数保存**：建议记录有效的参数设置以便重复使用

## 技术支持

如在使用过程中遇到任何问题，请：
1. 检查数据格式是否正确
2. 确认文件路径是否有效
3. 查看控制台输出的错误信息
4. 联系技术支持团队获取帮助